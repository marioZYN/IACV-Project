{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "from ast import literal_eval\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patch Extraction Example  \n",
    "I use blob detection to extract the dotted-area in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data initialization\n",
    "classes = [\"adult_males\", \"subadult_males\", \"adult_females\", \"juveniles\", \"pups\", \"total\"]\n",
    "\n",
    "train_path = '/Users/YINAN/Local/Sea-lions/Data/Train/'\n",
    "train_dotted_path = '/Users/YINAN/Local/Sea-lions/Data/TrainDotted/'\n",
    "\n",
    "bad_images = [3,7,9,21,30,34,71,81,89,97,151,184,215,234,242,268,290,311,331,344,380,384,406,421,469,475,490,499,507,\n",
    "              530,531,605,607,614,621,638,644,687,712,721]\n",
    "\n",
    "file_names = [str(x) + '.jpg' for x in range(0,750) if x not in bad_images]\n",
    "coordinates_df = pd.DataFrame(index=file_names, columns=classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_df = pd.read_csv(\"./coordinates.csv\", index_col='index', converters={\"total\": literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get coordinates\n",
    "start = time.time()\n",
    "\n",
    "for filename in file_names:\n",
    "\n",
    "    # read the Train and Train Dotted images\n",
    "    image_1 = cv2.imread(train_dotted_path + filename)\n",
    "    image_2 = cv2.imread(train_path + filename)\n",
    "\n",
    "    # absolute difference between Train and Train Dotted\n",
    "    image_3 = cv2.absdiff(image_1,image_2)\n",
    "\n",
    "    # mask out blackened regions from Train Dotted\n",
    "    mask_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n",
    "    mask_1[mask_1 < 20] = 0\n",
    "    mask_1[mask_1 > 0] = 255\n",
    "\n",
    "    mask_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2GRAY)\n",
    "    mask_2[mask_2 < 20] = 0\n",
    "    mask_2[mask_2 > 0] = 255\n",
    "\n",
    "    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_1)\n",
    "    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_2) \n",
    "\n",
    "    # convert to grayscale to be accepted by skimage.feature.blob_log\n",
    "    image_3 = cv2.cvtColor(image_3, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect blobs\n",
    "    blobs = skimage.feature.blob_log(image_3, min_sigma=3, max_sigma=4, num_sigma=1, threshold=0.02)\n",
    "    \n",
    "\n",
    "    adult_males = []\n",
    "    subadult_males = []\n",
    "    pups = []\n",
    "    juveniles = []\n",
    "    adult_females = []\n",
    "    total = []\n",
    "\n",
    "    for blob in blobs:\n",
    "        # get the coordinates for each blob\n",
    "        y, x, s = blob\n",
    "        # get the color of the pixel from Train Dotted in the center of the blob\n",
    "        g,b,r = image_1[int(y)][int(x)][:]\n",
    "\n",
    "        # decision tree to pick the class of the blob by looking at the color in Train Dotted\n",
    "        if r > 200 and g < 50 and b < 50: # RED\n",
    "            adult_males.append((int(x),int(y)))        \n",
    "        elif r > 200 and g > 200 and b < 50: # MAGENTA\n",
    "            subadult_males.append((int(x),int(y)))         \n",
    "        elif r < 100 and g < 100 and 150 < b < 200: # GREEN\n",
    "            pups.append((int(x),int(y)))\n",
    "        elif r < 100 and  100 < g and b < 100: # BLUE\n",
    "            juveniles.append((int(x),int(y))) \n",
    "        elif r < 150 and g < 50 and b < 100:  # BROWN\n",
    "            adult_females.append((int(x),int(y)))\n",
    "            \n",
    "        total.append((int(x), int(y)))\n",
    "\n",
    "    coordinates_df[\"adult_males\"][filename] = adult_males\n",
    "    coordinates_df[\"subadult_males\"][filename] = subadult_males\n",
    "    coordinates_df[\"adult_females\"][filename] = adult_females\n",
    "    coordinates_df[\"juveniles\"][filename] = juveniles\n",
    "    coordinates_df[\"pups\"][filename] = pups\n",
    "    coordinates_df[\"total\"][filename] = total\n",
    "    \n",
    "    print(\"\\r%s completes...\"%filename, end='')\n",
    "print(\"\\ncompletes!!!\")\n",
    "print(\"total time is {:.2f} minutes\".format((time.time() - start) / 60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_patches_with_sealions(coordinates_df):\n",
    "    patches = []\n",
    "    for filename in coordinates_df.index:\n",
    "        image = cv2.imread(train_path + filename)\n",
    "        for coordinates in coordinates_df.loc[filename].total:\n",
    "            thumb = image[coordinates[1]-48:coordinates[1]+48,coordinates[0]-48:coordinates[0]+48,:]\n",
    "            if np.shape(thumb) == (96, 96, 3):\n",
    "                patches.append(cv2.cvtColor(thumb, cv2.COLOR_BGR2RGB))\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patches = extract_patches(coordinates_df.sample(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_sealions(patches):\n",
    "    sealions = []\n",
    "    for patch in patches:\n",
    "        R = np.average(patch[:,:,0])\n",
    "        G = np.average(patch[:,:,1])\n",
    "        B = np.average(patch[:,:,2])\n",
    "        if B >= R and B >= G:\n",
    "            continue\n",
    "        sealions.append(patch)\n",
    "    return sealions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealions = check_sealions(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3363"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3190"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sealions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.85578352661315"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3190/3363*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract 96 x 96 patches\n",
    "x = []\n",
    "y = []\n",
    "for filename in file_names:    \n",
    "    image = cv2.imread(\"./data/train/\" + filename)\n",
    "    for lion_class in classes:\n",
    "        for coordinates in coordinates_df[lion_class][filename]:\n",
    "            thumb = image[coordinates[1]-48:coordinates[1]+48,coordinates[0]-48:coordinates[0]+48,:]\n",
    "            if np.shape(thumb) == (96, 96, 3):\n",
    "                x.append(cv2.cvtColor(thumb, cv2.COLOR_BGR2RGB))\n",
    "                y.append(lion_class)\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot examples\n",
    "for lion_class in classes:\n",
    "    f, ax = plt.subplots(1,10,figsize=(24,3))\n",
    "    f.suptitle(lion_class)\n",
    "    axes = ax.flatten()\n",
    "    j = 0\n",
    "    for a in axes:\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "        for i in range(j,len(x)):\n",
    "            if y[i] == lion_class:\n",
    "                j = i+1\n",
    "                a.imshow(x[i])\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_error(n):\n",
    "    error = 0\n",
    "    for i in range(n):\n",
    "        if i in bad_images: continue\n",
    "        standard = stat_df.iloc[i][1:]\n",
    "        calculate = list(map(lambda x: len(x), list(coordinates_df.loc[str(i)+'.jpg'])))[:-1]\n",
    "        e = sum(abs(standard - calculate))\n",
    "        if e > 10:\n",
    "            print(i)\n",
    "        error += e\n",
    "    return error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stat_df = pd.read_csv('/Users/YINAN/Local/Sea-lions/Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calculate_error(len(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_df.iloc[590]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coordinates_df.loc['0.jpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding window to extract patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3744, 5616, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_name = '0.jpg'\n",
    "test = cv2.imread(train_path + test_image_name)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_patches_with_sealions(coordinates_df):\n",
    "    patches = []\n",
    "    for filename in coordinates_df.index:\n",
    "        image = cv2.imread(train_path + filename)\n",
    "        for coordinates in coordinates_df.loc[filename].total:\n",
    "            thumb = image[coordinates[1]-48:coordinates[1]+48,coordinates[0]-48:coordinates[0]+48,:]\n",
    "            if np.shape(thumb) == (96, 96, 3):\n",
    "                patches.append(cv2.cvtColor(thumb, cv2.COLOR_BGR2RGB))\n",
    "    return patches\n",
    "\n",
    "\n",
    "\n",
    "def extract_sealions_without_sealions(coordinates_df):\n",
    "    patches = []\n",
    "    for filename in coordinates_df.index:\n",
    "        sealion_coordinates_list = coordinates_df.loc[filename].total\n",
    "        image = cv2.imread(train_path + filename)\n",
    "        for row in range(image.shape[0]//96):\n",
    "            for col in range(image.shape[1]//96):\n",
    "                center = (row*96+48, col*96+48)\n",
    "                flag = True\n",
    "                for thumb in sealion_coordinates_list:\n",
    "                    if math.sqrt((center[0] - thumb[1])**2 + (center[1] - thumb[0])**2) < math.sqrt(2)*96:\n",
    "                        flag = False\n",
    "                        break\n",
    "                if flag:\n",
    "                    patch_rgb = cv2.cvtColor(image[row*96:row*96+96, col*96:col*96+96], cv2.COLOR_BGR2RGB)\n",
    "                    patches.append(patch_rgb)\n",
    "    return patches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patches = []\n",
    "for row in range(0, test.shape[0]//96):\n",
    "    for col in range(0, test.shape[1]//96):    \n",
    "        center = (row*96+48, col*96+48)\n",
    "        flag = True\n",
    "        for thumb in coordinates_df.loc['0.jpg'].total:\n",
    "            if math.sqrt((center[0] - thumb[1])**2 + (center[1] - thumb[0])**2) < math.sqrt(2)*96:\n",
    "                flag = False\n",
    "                break\n",
    "        if flag:\n",
    "            patch_rgb = cv2.cvtColor(test[row*96:row*96+96, col*96:col*96+96], cv2.COLOR_BGR2RGB)\n",
    "            patches.append(patch_rgb)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1014"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "946"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coordinates_df.loc['0.jpg'].total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = check_sealions(patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO\n",
    "* using logistic regression to classify images\n",
    "* generate pos and neg patches\n",
    "* train the classifier \n",
    "* test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract pos patches\n",
    "pos_df = pd.DataFrame(columns=[\"R\", \"G\", \"B\"])\n",
    "patches = extract_patches(coordinates_df=coordinates_df.head(1))\n",
    "\n",
    "for i in range(len(patches)):\n",
    "    patch = patches[i]\n",
    "    r = np.average(patch[:,:,0])\n",
    "    g = np.average(patch[:,:,1])\n",
    "    b = np.average(patch[:,:,2])\n",
    "    pos_df = pos_df.append({'R':r, \"G\":g, \"B\":b}, ignore_index=True)\n",
    "\n",
    "pos_df['class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract neg patches\n",
    "neg_df = pd.DataFrame(columns=[\"R\", \"G\", \"B\"])\n",
    "\n",
    "for i in range(len(patches)):\n",
    "    patch = patches[i]\n",
    "    r = np.average(patch[:,:,0])\n",
    "    g = np.average(patch[:,:,1])\n",
    "    b = np.average(patch[:,:,2])\n",
    "    neg_df = neg_df.append({'R':r, \"G\":g, \"B\":b}, ignore_index=True)\n",
    "\n",
    "neg_df['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pos_df.append(neg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93059936908517349"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### build logistic regression \n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "target = 'class'\n",
    "variables = total.columns[total.columns != target]\n",
    "\n",
    "x_train, x_test,y_train, y_test = \\\n",
    "model_selection.train_test_split(total[[\"B\", \"G\", 'R']], total[target], test_size = 0.33, random_state=11)\n",
    "\n",
    "logistic = linear_model.LogisticRegression(C=10e10, random_state=1234)\n",
    "logistic.fit(x_train, y_train)\n",
    "\n",
    "y_pred = logistic.predict(x_test)\n",
    "\n",
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_patches_with_sealions(coordinates_df):\n",
    "    patches = []\n",
    "    count = 0\n",
    "    for filename in coordinates_df.index:\n",
    "        count += 1\n",
    "        image = cv2.imread(train_path + filename)\n",
    "        for coordinates in coordinates_df.loc[filename].total:\n",
    "            thumb = image[coordinates[1]-48:coordinates[1]+48,coordinates[0]-48:coordinates[0]+48,:]\n",
    "            if np.shape(thumb) == (96, 96, 3):\n",
    "                patches.append(cv2.cvtColor(thumb, cv2.COLOR_BGR2RGB))\n",
    "        print(\"\\r%d file completes, with total %d\"%(count, len(coordinates_df)), end='')\n",
    "    return patches\n",
    "\n",
    "\n",
    "\n",
    "def extract_patches_without_sealions(coordinates_df):\n",
    "    patches = []\n",
    "    count = 0\n",
    "    for filename in coordinates_df.index:\n",
    "        sealion_coordinates_list = coordinates_df.loc[filename].total\n",
    "        image = cv2.imread(train_path + filename)\n",
    "        count += 1\n",
    "        for row in range(image.shape[0]//96):\n",
    "            for col in range(image.shape[1]//96):\n",
    "                center = (row*96+48, col*96+48)\n",
    "                flag = True\n",
    "                for thumb in sealion_coordinates_list:\n",
    "                    if math.sqrt((center[0] - thumb[1])**2 + (center[1] - thumb[0])**2) < math.sqrt(2)*96:\n",
    "                        flag = False\n",
    "                        break\n",
    "                if flag:\n",
    "                    patch_rgb = cv2.cvtColor(image[row*96:row*96+96, col*96:col*96+96], cv2.COLOR_BGR2RGB)\n",
    "                    patches.append(patch_rgb)\n",
    "        print(\"\\r%d file completes, with total %d\"%(count, len(coordinates_df)), end='')\n",
    "    return patches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 file completes, with total 300"
     ]
    }
   ],
   "source": [
    "### extract pos patches\n",
    "pos_df = pd.DataFrame(columns=[\"R\", \"G\", \"B\"])\n",
    "patches = extract_patches_with_sealions(coordinates_df=coordinates_df.sample(300))\n",
    "\n",
    "for i in range(len(patches)):\n",
    "    patch = patches[i]\n",
    "    r = np.average(patch[:,:,0])\n",
    "    g = np.average(patch[:,:,1])\n",
    "    b = np.average(patch[:,:,2])\n",
    "    pos_df = pos_df.append({'R':r, \"G\":g, \"B\":b}, ignore_index=True)\n",
    "\n",
    "pos_df['class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 file completes, with total 15"
     ]
    }
   ],
   "source": [
    "### extract neg patches\n",
    "neg_df = pd.DataFrame(columns=[\"R\", \"G\", \"B\"])\n",
    "patches = extract_patches_without_sealions(coordinates_df=coordinates_df.sample(15))\n",
    "\n",
    "for i in range(len(patches)):\n",
    "    patch = patches[i]\n",
    "    r = np.average(patch[:,:,0])\n",
    "    g = np.average(patch[:,:,1])\n",
    "    b = np.average(patch[:,:,2])\n",
    "    neg_df = neg_df.append({'R':r, \"G\":g, \"B\":b}, ignore_index=True)\n",
    "\n",
    "neg_df['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28819"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26764"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = pos_df.append(neg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall score is 0.8012102196324519\n",
      "precision score is 0.7785278745644599\n"
     ]
    }
   ],
   "source": [
    "### build logistic regression \n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "target = 'class'\n",
    "variables = total.columns[total.columns != target]\n",
    "\n",
    "x_train, x_test,y_train, y_test = \\\n",
    "model_selection.train_test_split(total[[\"B\", \"G\", 'R']], total[target], test_size = 0.33, random_state=11)\n",
    "\n",
    "logistic = linear_model.LogisticRegression(C=1, random_state=1234)\n",
    "logistic.fit(x_train, y_train)\n",
    "\n",
    "y_pred = logistic.predict(x_test)\n",
    "\n",
    "print(\"recall score is {}\".format(recall_score(y_test, y_pred)))\n",
    "print(\"precision score is {}\".format(precision_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2581087 ,  0.7418913 ],\n",
       "       [ 0.63594455,  0.36405545],\n",
       "       [ 0.75313516,  0.24686484],\n",
       "       [ 0.24557914,  0.75442086],\n",
       "       [ 0.22792968,  0.77207032],\n",
       "       [ 0.49220043,  0.50779957],\n",
       "       [ 0.94375765,  0.05624235],\n",
       "       [ 0.13003474,  0.86996526],\n",
       "       [ 0.54873745,  0.45126255],\n",
       "       [ 0.19137663,  0.80862337]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.predict_proba(x_test)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassifyWithThreshold(probabilities, threshold):\n",
    "    return [+1 if x>=threshold else 0 for x in probabilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_new = ClassifyWithThreshold(logistic.predict_proba(x_test)[:,1], 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97725235320484083"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50789121192708642"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2581087 ,  0.7418913 ],\n",
       "       [ 0.63594455,  0.36405545],\n",
       "       [ 0.75313516,  0.24686484],\n",
       "       ..., \n",
       "       [ 0.6111643 ,  0.3888357 ],\n",
       "       [ 0.70157573,  0.29842427],\n",
       "       [ 0.94388032,  0.05611968]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
